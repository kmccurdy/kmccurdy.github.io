
@article{mccurdy_regularization_2022,
	data = {cogsci2022_study4_data.zip},
	address = {Toronto, CA},
	title = {Regularization and its discontents: When speakers conditionally probability-match the lexicon},
	copyright = {All rights reserved},
	abstract = {Artificial language learning research has shown that, under some conditions, adult speakers tend to \textit{probability-match} to inconsistent variation in their input, while in others, they \textit{regularize} by reducing that variation. We demonstrate that this framework can characterize speaker behavior in a natural-language morphological inflection task: even without a variable input distribution, the lexicon can be used to estimate variation in speaker productions. In the task of German plural inflection, we find that speakers probability-match a lexical distribution conditioned on phonology, and largely disregard an alternative possible strategy of conditional regularization based on grammatical gender.},
	journal = {To appear at CogSci},
	author = {McCurdy, Kate and Goldwater, Sharon and Lopez, Adam},
	year = {2022}
}

@inproceedings{dankers_generalising_2021,
	address = {Online},
	title = {Generalising to {German} {Plural} {Noun} {Classes}, from the {Perspective} of a {Recurrent} {Neural} {Network}},
	url = {https://aclanthology.org/2021.conll-1.8},
	abstract = {Inflectional morphology has since long been a useful testing ground for broader questions about generalisation in language and the viability of neural network models as cognitive models of language. Here, in line with that tradition, we explore how recurrent neural networks acquire the complex German plural system and reflect upon how their strategy compares to human generalisation and rule-based models of this system. We perform analyses including behavioural experiments, diagnostic classification, representation analysis and causal interventions, suggesting that the models rely on features that are also key predictors in rule-based models of German plurals. However, the models also display shortcut learning, which is crucial to overcome in search of more cognitively plausible generalisation behaviour.},
	booktitle = {Proceedings of the 25th {Conference} on {Computational} {Natural} {Language} {Learning} (CoNLL)},
	publisher = {Association for Computational Linguistics},
	author = {Dankers, Verna and Langedijk, Anna and McCurdy, Kate and Williams, Adina and Hupkes, Dieuwke},
	month = nov,
	year = {2021},
	pages = {94--108},
	note = {Best Paper Award.}
}


@inproceedings{mccurdy_adaptor_2021,
	code = {https://github.com/kmccurdy/paradigm-clusters},
	address = {Online},
	title = {Adaptor {Grammars} for {Unsupervised} {Paradigm} {Clustering}},
	copyright = {All rights reserved},
	url = {https://aclanthology.org/2021.sigmorphon-1.9},
	doi = {10.18653/v1/2021.sigmorphon-1.9},
	abstract = {This work describes the Edinburgh submission to the SIGMORPHON 2021 Shared Task 2 on unsupervised morphological paradigm clustering. Given raw text input, the task was to assign each token to a cluster with other tokens from the same paradigm. We use Adaptor Grammar segmentations combined with frequency-based heuristics to predict paradigm clusters. Our system achieved the highest average F1 score across 9 test languages, placing first out of 15 submissions.},
	language = {en},
	urldate = {2021-08-18},
	booktitle = {Proceedings of the 18th {SIGMORPHON} {Workshop} on {Computational} {Research} in {Phonetics}, {Phonology}, and {Morphology}},
	publisher = {Association for Computational Linguistics},
	author = {McCurdy, Kate and Goldwater, Sharon and Lopez, Adam},
	year = {2021},
	pages = {82--89},
	note = {Winning shared task submission.}
}


@inproceedings{mccurdy-etal-2020-conditioning,
    title = "Conditioning, but on Which Distribution? Grammatical Gender in {G}erman Plural Inflection",
    author = "McCurdy, Kate  and
      Lopez, Adam  and
      Goldwater, Sharon",
    booktitle = "Proceedings of the Workshop on Cognitive Modeling and Computational Linguistics",
	data = {cmcl2020_study2_data.zip},
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.cmcl-1.8",
    pages = "59--65",
    poster = "CMCLposter.pdf",
    abstract = "Grammatical gender is a consistent and informative cue to the plural class of German nouns. We find that neural encoder-decoder models learn to rely on this cue to predict plural class, but adult speakers are relatively insensitive to it. This suggests that the neural models are not an effective cognitive model of German plural formation.",
}


@article{mccurdy_grammatical_2017,
	code = {https://github.com/kmccurdy/w2v-gender},
	arxiv = {arXiv:2005.08864},
	address = {Vancouver, Canada},
	title = {Grammatical gender associations outweigh topical gender bias in crosslinguistic word embeddings},
	copyright = {All rights reserved},
	url = {http://www.winlp.org/wp-content/uploads/2017/final_papers_2017/46_Paper.pdf},
	abstract = {Recent research has demonstrated that vector space models of semantics can reﬂect undesirable biases in human culture. Our investigation of crosslinguistic word embeddings reveals that topical gender bias interacts with, and is surpassed in magnitude by, the effect of grammatical gender associations, and both may be attenuated by corpus lemmatization. This ﬁnding has implications for downstream applications such as machine translation.},
	language = {en},
	journal = {Presented at {WiNLP} ({Women} in {Natural} {Language} {Processing})},
	author = {McCurdy, Katherine and Serbetçi, Oğuz},
	year = {2017},
	file = {McCurdy - Grammatical gender associations outweigh topical g.pdf:/Users/kate/Zotero/storage/UQUHURR7/McCurdy - Grammatical gender associations outweigh topical g.pdf:application/pdf}
}

@inproceedings{sinclair_tutorbot_2019,
	address = {Montreal},
	title = {Tutorbot {Corpus}: {Evidence} of {Human}-{Agent} {Verbal} {Alignment} in {Second} {Language} {Learner} {Dialogues}},
	copyright = {All rights reserved},
	url = {https://files.eric.ed.gov/fulltext/ED599239.pdf},
	abstract = {Prior research has shown that, under certain conditions, Human-Agent (H-A) alignment exists to a stronger degree than that found in Human-Human (H-H) communication. In an H-H Second Language (L2) setting, evidence of alignment has been linked to learning and teaching strategy. We present a novel analysis of H-A and H-H L2 learner dialogues using automated metrics of alignment. Our contributions are twofold: ﬁrstly we replicated the reported H-A alignment within an educational context, ﬁnding L2 students align to an automated tutor. Secondly, we performed an exploratory comparison of the alignment present in comparable H-A and H-H L2 learner corpora using Bayesian Gaussian Mixture Models (GMMs), ﬁnding preliminary evidence that students in H-A L2 dialogues showed greater variability in engagement.},
	language = {en},
	booktitle = {Proceedings of the 12th {International} {Conference} on {Educational} {Data} {Mining}},
	author = {Sinclair, Arabella and McCurdy, Kate and Lucas, Christopher G and Lopez, Adam and Gašević, Dragan},
	year = {2019},
	file = {Sinclair et al. - 2019 - Tutorbot Corpus Evidence of Human-Agent Verbal Al.pdf:/Users/kate/Zotero/storage/G6WJUIQH/Sinclair et al. - 2019 - Tutorbot Corpus Evidence of Human-Agent Verbal Al.pdf:application/pdf}
}

@inproceedings{loughnane_linked_2017,
	address = {Copenhagen, Denmark},
	title = {Linked {Data} for {Language}-{Learning} {Applications}},
	copyright = {All rights reserved},
	url = {https://www.aclweb.org/anthology/W17-5005},
	doi = {10.18653/v1/W17-5005},
	abstract = {The use of linked data within language-learning applications is an open research question. A research prototype is presented that applies linked-data principles to store linguistic annotation generated from language-learning content using a variety of NLP tools. The result is a database that links learning content, linguistic annotation and open-source resources, on top of which a diverse range of tools for language-learning applications can be built.},
	urldate = {2019-09-06},
	booktitle = {Proceedings of the 12th {Workshop} on {Innovative} {Use} of {NLP} for {Building} {Educational} {Applications}},
	publisher = {Association for Computational Linguistics},
	author = {Loughnane, Robyn and McCurdy, Kate and Kolb, Peter and Selent, Stefan},
	month = sep,
	year = {2017},
	pages = {44--51},
	file = {Full Text PDF:/Users/kate/Zotero/storage/2M2VTEJC/Loughnane et al. - 2017 - Linked Data for Language-Learning Applications.pdf:application/pdf}
}

@inproceedings{mccurdy_inflecting_2020,
	arxiv = {arXiv: 2005.08826},
	data = {acl2020_study1_data.zip},
	blog = {/acl2020-summary},
	address = {Online},
	title = {Inflecting {When} {There}'s {No} {Majority}: {Limitations} of {Encoder}-{Decoder} {Neural} {Networks} as {Cognitive} {Models} for {German} {Plurals}},
	copyright = {All rights reserved},
	shorttitle = {Inflecting {When} {There}'s {No} {Majority}},
	url = {https://www.aclweb.org/anthology/2020.acl-main.159},
	abstract = {Can artificial neural networks learn to represent inflectional morphology and generalize to new words as human speakers do? Kirov and Cotterell (2018) argue that the answer is yes: modern Encoder-Decoder (ED) architectures learn human-like behavior when inflecting English verbs, such as extending the regular past tense form /-(e)d/ to novel words. However, their work does not address the criticism raised by Marcus et al. (1995): that neural models may learn to extend not the regular, but the most frequent class — and thus fail on tasks like German number inflection, where infrequent suffixes like /-s/ can still be productively generalized. To investigate this question, we first collect a new dataset from German speakers (production and ratings of plural forms for novel nouns) that is designed to avoid sources of information unavailable to the ED model. The speaker data show high variability, and two suffixes evince `regular' behavior, appearing more often with phonologically atypical inputs. Encoder-decoder models do generalize the most frequently produced plural class, but do not show human-like variability or `regular' extension of these other plural markers. We conclude that modern neural models may still struggle with minority-class generalization.},
	urldate = {2020-07-21},
	booktitle = {Proceedings of the 58th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {McCurdy, Kate and Goldwater, Sharon and Lopez, Adam},
	month = jul,
	year = {2020},
	pages = {1745--1756},
	file = {Full Text PDF:/Users/kate/Zotero/storage/RPCJXYY2/McCurdy et al. - 2020 - Inflecting When There's No Majority Limitations o.pdf:application/pdf}
}

@inproceedings{mccurdy_modeling_2020,
	title = {Modeling grammatical gender and plural inflection in {German}},
	copyright = {All rights reserved},
	data = {amlap2020_study3_data.zip},
	url = {https://amlap2020.github.io/a/261.pdf},
	booktitle = {Proceedings of the 26 {Architectures} and {Mechanisms} for {Language} {Processing} {Conference} ({AMLaP})},
	publisher = {Universität Potsdam},
	author = {McCurdy, Kate and Lopez, Adam and Goldwater, Sharon},
	month = sep,
	year = {2020},
	file = {261.pdf:/Users/kate/Zotero/storage/E4UI62KX/261.pdf:application/pdf}
}

@article{wagner_poetic_2010,
	title = {Poetic rhyme reflects cross-linguistic differences in information structure},
	volume = {117},
	copyright = {All rights reserved},
	issn = {0010-0277},
	url = {http://www.sciencedirect.com/science/article/pii/S0010027710001769},
	doi = {10.1016/j.cognition.2010.08.007},
	abstract = {Identical rhymes (right/write, attire/retire) are considered satisfactory and even artistic in French poetry but are considered unsatisfactory in English. This has been a consistent generalization over the course of centuries, a surprising fact given that other aspects of poetic form in French were happily applied in English. This paper puts forward the hypothesis that this difference is not merely one of poetic tradition, but is grounded in the distinct ways in which information-structure affects prosody in the two languages. A study of rhyme usage in poetry and a perception experiment confirm that native speakers’ intuitions about rhyming in the two languages indeed differ, and a further perception experiment supports the hypothesis that this fact is due to a constraint on prosody that is active in English but not in French. The findings suggest that certain forms of artistic expression in poetry are influenced, and even constrained, by more general properties of a language.},
	language = {en},
	number = {2},
	urldate = {2020-09-10},
	journal = {Cognition},
	author = {Wagner, Michael and McCurdy, Katherine},
	month = nov,
	year = {2010},
	keywords = {Focus, Givenness, Information structure, Poetry, Prosody, Rhyme},
	pages = {166--175},
	file = {ScienceDirect Full Text PDF:/Users/kate/Zotero/storage/ZSGMZT78/Wagner and McCurdy - 2010 - Poetic rhyme reflects cross-linguistic differences.pdf:application/pdf;ScienceDirect Snapshot:/Users/kate/Zotero/storage/PI9G7WCQ/S0010027710001769.html:text/html}
}

@article{mccurdy_implicit_2013,
	title = {Implicit prosody and contextual bias in silent reading},
	volume = {6},
	copyright = {Copyright (c)},
	issn = {1995-8692},
	url = {https://bop.unibe.ch/JEMR/article/view/2357},
	doi = {10.16910/jemr.6.2.4},
	abstract = {Eye-movement research on implicit prosody has found effects of lexical stress on syntactic ambiguity resolution, suggesting that metrical well-formedness constraints interact with syntactic category assignment. Building on these findings, the present eyetracking study investigates whether contextual bias can modulate the effects of metrical structure on syntactic ambiguity resolution in silent reading. Contextual bias and potential stress-clash in the ambiguous region were crossed in a 2 2 design. Participants read biased context sentences followed by temporarily ambiguous test sentences. In the three-word ambiguous region, main effects of lexical stress were dominant, while early effects of context were absent. Potential stress clash yielded a significant increase in first-pass regressions and re-reading probability across the three words. In the disambiguating region, the disambiguating word itself showed increased processing difficulty (lower skipping and increased re-reading probability) when the disambiguation engendered a stress clash configuration, while the word immediately following showed main effects of context in those same measures. Taken together, effects of lexical stress upon eye movements were swift and pervasive across first-pass and second-pass measures, while effects of context were relatively delayed. These results indicate a strong role for implicit meter in guiding parsing, one that appears insensitive to higher-level constraints. Our findings are problematic for two classes of models, the two-stage garden-path model and the constraint-based competition-integration model, but can be explained by a variation on the two-stage model, the unrestricted race model.},
	language = {en},
	number = {2},
	urldate = {2020-09-10},
	journal = {Journal of Eye Movement Research},
	author = {McCurdy, Kate and Kentner, Gerrit and Vasishth, Shravan},
	month = jul,
	year = {2013},
	note = {Number: 2},
	keywords = {context, implicit meter, re-reading probability, reanalysis, silent prosody, skipping rate, stress-clash, unrestricted race model},
	file = {Full Text PDF:/Users/kate/Zotero/storage/RXBPYVFD/McCurdy et al. - 2013 - Implicit prosody and contextual bias in silent rea.pdf:application/pdf;Snapshot:/Users/kate/Zotero/storage/W5PE7XNI/2357.html:text/html}
}
